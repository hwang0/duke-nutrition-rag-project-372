{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duke Nutrition Assistant CS 372 Project - Notebook 2: Create Embeddings\n",
    "## Step 2: Embed Menu Items for Retrieval (MPS GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0\n",
      "MPS available: True\n",
      "MPS built: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS built: {torch.backends.mps.is_built()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon GPU)\n",
      "\n",
      "Device set to: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Using CPU (no GPU detected)\")\n",
    "\n",
    "print(f\"\\nDevice set to: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Processed Menu Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 1,644 menu items\n",
      "After filtering: 1,637 menu items\n",
      "Dropped: 7 items\n"
     ]
    }
   ],
   "source": [
    "# Load the processed data from Notebook 1\n",
    "with open('data/menu_processed.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "documents = data['documents']\n",
    "items = data['items']\n",
    "\n",
    "print(f\"Original: {len(documents):,} menu items\")\n",
    "\n",
    "# Some extra removals\n",
    "items_to_drop = [\n",
    "    'Powdered Sugar', 'White Sugar', 'Vanilla Whey Protein', 'Chocolate Whey Protein Boost', 'Almond Milk', 'Coconut Milk', 'Oat Milk', 'Soy Milk', 'Plain Yogurt', 'Green Apple', 'Avocado', 'Banana', 'Blueberries', 'Chia Seeds', 'Shredded Coconut', 'Granola', 'Mangoes', 'Nutella', 'Peanut Butter', 'Spinach', 'Strawberries', 'Vegan Protein', 'Chocolate Whey Protein', 'Vanilla Whey Protein', 'Brown Sugar', 'Raisins',\n",
    "    'Egg Your Way',\n",
    "    'Sugar Free Maple Syrup', 'Maple Flavored Syrup', 'Smart Balance', 'Butter', 'Maple Syrup',\n",
    "    'Fettuccine',\n",
    "    'Spaghetti', 'Ketchup'\n",
    "]\n",
    "\n",
    "# create filtered lists\n",
    "filtered_documents = []\n",
    "filtered_items = []\n",
    "\n",
    "for doc, item in zip(documents, items):\n",
    "    # skip if item name is in drop list\n",
    "    if item['item_name'] not in items_to_drop:\n",
    "        filtered_documents.append(doc)\n",
    "        filtered_items.append(item)\n",
    "\n",
    "# Replace original lists\n",
    "documents = filtered_documents\n",
    "items = filtered_items\n",
    "\n",
    "print(f\"After filtering: {len(documents):,} menu items\")\n",
    "print(f\"Dropped: {len(data['documents']) - len(documents)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Model loaded successfully on mps!\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model (same as from homework)\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "print(f\"Loading model: {embedding_model_name}\")\n",
    "\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "embedding_model = AutoModel.from_pretrained(embedding_model_name)\n",
    "\n",
    "# Move to MPS device\n",
    "embedding_model = embedding_model.to(device)\n",
    "embedding_model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(f\"Model loaded successfully on {device}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Embeddings Function\n",
    "\n",
    "**This function is COPIED EXACTLY from RAG homework with MPS compatibility!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding function ready!\n",
      " Retrieval functions ready!\n"
     ]
    }
   ],
   "source": [
    "def compute_embeddings(texts, model, tokenizer, batch_size=32, device=\"mps\"):\n",
    "    \"\"\"\n",
    "    Compute dense embeddings for a list of texts.\n",
    "        \n",
    "    Args:\n",
    "        texts: List of strings to embed\n",
    "        model: Sentence transformer model\n",
    "        tokenizer: Model tokenizer\n",
    "        batch_size: Number of texts to process at once\n",
    "        device: Device to use ('mps', 'cuda', or 'cpu')\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape (len(texts), embedding_dim)\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Computing embeddings\"):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            \n",
    "            # Tokenize batch\n",
    "            inputs = tokenizer(batch, \n",
    "                             return_tensors='pt',\n",
    "                             padding=True, \n",
    "                             truncation=True,\n",
    "                             max_length=512)\n",
    "            \n",
    "            # Move to device (MPS)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # Mean pooling (from RAG homework)\n",
    "            pooled = outputs.last_hidden_state.mean(dim=1)\n",
    "            \n",
    "            # Move to CPU and convert to numpy\n",
    "            pooled_np = pooled.cpu().numpy()\n",
    "            embeddings.append(pooled_np)\n",
    "    \n",
    "    # Stack all batches\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "print(\"Embedding function ready!\")\n",
    "def retrieve_top_k(query, context_embeddings, contexts, model, tokenizer, device, k=5):\n",
    "    \"\"\"\n",
    "    Retrieve top-k most similar menu items.\n",
    "    FROM RAG HOMEWORK\n",
    "    \"\"\"\n",
    "    query_embedding = compute_embeddings([query], model, tokenizer, \n",
    "                                        batch_size=1, device=device)[0]\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    dot_product = np.dot(context_embeddings, query_embedding)\n",
    "    norms = (np.linalg.norm(context_embeddings, axis=1) * \n",
    "            np.linalg.norm(query_embedding))\n",
    "    similarities = dot_product / norms\n",
    "    \n",
    "    # Get top-k indices\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            'index': int(idx),\n",
    "            'document': contexts[idx],\n",
    "            'item_name': items[idx]['item_name'],\n",
    "            'restaurant': items[idx]['restaurant'],\n",
    "            'score': float(similarities[idx]),\n",
    "            'item': items[idx]  # Full item details\n",
    "        }\n",
    "        for idx in top_indices\n",
    "    ]\n",
    "\n",
    "print(\" Retrieval functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a Few Items First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing embedding on 5 items...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████████| 1/1 [00:00<00:00,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test embeddings shape: (5, 384)\n",
      "   Embedding dimension: 384\n",
      "\n",
      " First embedding (first 10 values):\n",
      "   [-0.16062553 -0.10292386 -0.05305719  0.16567005 -0.11824609 -0.02903908\n",
      "  0.06736976 -0.13347669 -0.21786804 -0.11153291]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on first 5 items\n",
    "test_docs = documents[:5]\n",
    "print(\" Testing embedding on 5 items...\\n\")\n",
    "\n",
    "test_embeddings = compute_embeddings(test_docs, embedding_model, \n",
    "                                    embedding_tokenizer, batch_size=5, device=device)\n",
    "\n",
    "print(f\"\\n Test embeddings shape: {test_embeddings.shape}\")\n",
    "print(f\"   Embedding dimension: {test_embeddings.shape[1]}\")\n",
    "print(f\"\\n First embedding (first 10 values):\")\n",
    "print(f\"   {test_embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Embeddings for ALL Menu Items\n",
    "\n",
    "**On MPS (Apple Silicon), this should take 2-5 minutes for ~3,300 items.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Computing embeddings for 1,637 menu items...\n",
      "   Device: mps\n",
      "   Batch size: 32\n",
      "\n",
      " Estimated time on MPS: 2-5 minutes\n",
      "   (On CPU it would take 10-15 minutes)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|█████████████████████| 52/52 [00:05<00:00,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Embeddings computed in 5.3 seconds (0.1 minutes)!\n",
      " Embeddings shape: (1637, 384)\n",
      " Average time per item: 3.23ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute embeddings for all documents\n",
    "print(f\" Computing embeddings for {len(documents):,} menu items...\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Batch size: 32\")\n",
    "print(f\"\\n Estimated time on MPS: 2-5 minutes\")\n",
    "print(f\"   (On CPU it would take 10-15 minutes)\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "menu_embeddings = compute_embeddings(\n",
    "    documents, \n",
    "    embedding_model, \n",
    "    embedding_tokenizer,\n",
    "    batch_size=32, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n Embeddings computed in {elapsed_time:.1f} seconds ({elapsed_time/60:.1f} minutes)!\")\n",
    "print(f\" Embeddings shape: {menu_embeddings.shape}\")\n",
    "print(f\" Average time per item: {elapsed_time/len(documents)*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Embeddings saved to: models/menu_embeddings.npy\n",
      "   File size: 2.40 MB\n",
      " Metadata saved to: models/embedding_metadata.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "np.save('models/menu_embeddings.npy', menu_embeddings)\n",
    "\n",
    "metadata = {\n",
    "    'model_name': embedding_model_name,\n",
    "    'num_items': len(documents),\n",
    "    'embedding_dim': menu_embeddings.shape[1],\n",
    "    'device_used': device,\n",
    "    'computation_time_seconds': elapsed_time,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "with open('models/embedding_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "file_size = os.path.getsize('models/menu_embeddings.npy') / 1024 / 1024\n",
    "\n",
    "print(f\" Embeddings saved to: models/menu_embeddings.npy\")\n",
    "print(f\"   File size: {file_size:.2f} MB\")\n",
    "print(f\" Metadata saved to: models/embedding_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Loading Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded embeddings shape: (1637, 384)\n",
      " Matches original: True\n",
      "\n",
      " Embeddings can be loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#Check if loading matches og\n",
    "loaded_embeddings = np.load('models/menu_embeddings.npy')\n",
    "\n",
    "print(f\" Loaded embeddings shape: {loaded_embeddings.shape}\")\n",
    "print(f\" Matches original: {np.allclose(loaded_embeddings, menu_embeddings)}\")\n",
    "\n",
    "print(\"\\n Embeddings can be loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Retrieval Test\n",
    "\n",
    "Test if our embeddings work for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrieval function ready!\n"
     ]
    }
   ],
   "source": [
    "def retrieve_top_k(query, context_embeddings, contexts, model, tokenizer, device, k=5):\n",
    "    \"\"\"\n",
    "    Retrieve top-k most similar items.\n",
    "    \n",
    "    ADAPTED FROM RAG HOMEWORK retrieve_top_context()\n",
    "    \"\"\"\n",
    "    query_embedding = compute_embeddings([query], model, tokenizer, \n",
    "                                        batch_size=1, device=device)[0]\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    dot_product = np.dot(context_embeddings, query_embedding)\n",
    "    norms = (np.linalg.norm(context_embeddings, axis=1) * \n",
    "            np.linalg.norm(query_embedding))\n",
    "    similarities = dot_product / norms\n",
    "    \n",
    "    # Get top-k indices\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            'index': int(idx),\n",
    "            'document': contexts[idx],\n",
    "            'item_name': items[idx]['item_name'],\n",
    "            'restaurant': items[idx]['restaurant'],\n",
    "            'score': float(similarities[idx])\n",
    "        }\n",
    "        for idx in top_indices\n",
    "    ]\n",
    "\n",
    "print(\" Retrieval function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TESTING RETRIEVAL ON QUERIES\n",
      "\n",
      "================================================================================\n",
      "\n",
      " Query: 'high protein low calorie'\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████████| 1/1 [00:00<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Steak at The Pitchfork\n",
      "   Score: 0.580\n",
      "   Steak from The Pitchfork. Available during Lunch & Dinner. Nutrition: 120 calories, 20g protein, 4g fat, 30mg sodium. Macros: 67% protein, 30% fat. Ta...\n",
      "\n",
      "2. Protein Shot at Saladalia @ The Perk\n",
      "   Score: 0.574\n",
      "   Protein Shot from Saladalia @ The Perk. Available during Specialty Drinks. Nutrition: 70 calories, 10g protein, 2g fat, 5g carbs, 3g fiber, 110mg sodi...\n",
      "\n",
      "3. Chicken and Fresh Mozzarella Sandwich at Gothic Grill\n",
      "   Score: 0.568\n",
      "   Chicken and Fresh Mozzarella Sandwich from Gothic Grill. Available during Specialty Drinks. Nutrition: 750 calories, 72g protein, 24g fat, 55g carbs, ...\n",
      "\n",
      " Query: 'I want to lean bulk'\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████████| 1/1 [00:00<00:00, 41.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Skinny Strawberry Smoothie at Red Mango\n",
      "   Score: 0.385\n",
      "   Skinny Strawberry Smoothie from Red Mango. Available during Smoothies. Nutrition: 350 calories, 26g protein, 4g fat, 55g carbs, 4g fiber, 38g sugars, ...\n",
      "\n",
      "2. Mango Metabolizer Smoothie at Red Mango\n",
      "   Score: 0.369\n",
      "   Mango Metabolizer Smoothie from Red Mango. Available during Smoothies. Nutrition: 340 calories, 26g protein, 4g fat, 52g carbs, 3g fiber, 36g sugars, ...\n",
      "\n",
      "3. Mango Smoothie at Cafe\n",
      "   Score: 0.347\n",
      "   Mango Smoothie from Cafe. Available during Specialty Drinks. Nutrition: 510 calories, 3g protein, 1g fat, 128g carbs, 6g fiber, 135g sugars, 20mg sodi...\n",
      "\n",
      " Query: 'I need more fiber'\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████████| 1/1 [00:00<00:00, 55.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Bow Tie Pasta at Marketplace\n",
      "   Score: 0.409\n",
      "   Bow Tie Pasta from Marketplace. Available during Dinner. Nutrition: 270 calories, 10g protein, 2g fat, 53g carbs, 3g fiber. Dietary: Gluten Free; Vege...\n",
      "\n",
      "2. Raisin Bran at Marketplace\n",
      "   Score: 0.388\n",
      "   Raisin Bran from Marketplace. Available during Breakfast. Nutrition: 90 calories, 2g protein, 0g fat, 23g carbs, 3g fiber, 9g sugars, 105mg sodium. Di...\n",
      "\n",
      "3. Plain Bagel at Duke Marine Lab\n",
      "   Score: 0.381\n",
      "   Plain Bagel from Duke Marine Lab. Available during Breakfast. Nutrition: 1790 calories, 60g protein, 6g fat, 382g carbs, 12g fiber, 48g sugars, 2740mg...\n",
      "\n",
      " Query: 'keto friendly meal'\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████████| 1/1 [00:00<00:00, 56.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Two Eggs to Order Any Style at The Skillet\n",
      "   Score: 0.581\n",
      "   Two Eggs to Order Any Style from The Skillet. Available during Breakfast. Nutrition: 150 calories, 9g protein, 12g fat, 1g carbs, 1g sugars, 135mg sod...\n",
      "\n",
      "2. Carnitas at The Pitchfork\n",
      "   Score: 0.565\n",
      "   Carnitas from The Pitchfork. Available during Lunch & Dinner. Nutrition: 120 calories, 12g protein, 6g fat, 2g carbs, 2g sugars, 270mg sodium. Macros:...\n",
      "\n",
      "3. Mushroom at The Pitchfork\n",
      "   Score: 0.557\n",
      "   Mushroom from The Pitchfork. Available during Lunch & Dinner. Nutrition: 20 calories, 3g protein, 3g carbs, 1g fiber, 15mg sodium. Dietary: Vegan; Veg...\n",
      "\n",
      " Query: 'low sugar option'\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████████| 1/1 [00:00<00:00, 46.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Au Lait Skim Milk at Beyu Blue Coffee\n",
      "   Score: 0.437\n",
      "   Au Lait Skim Milk from Beyu Blue Coffee. Available during Specialty Drinks. Nutrition: 20 calories, 2g protein, 3g carbs, 3g sugars, 35mg sodium. Diet...\n",
      "\n",
      "2. Iced Mint 2 B U Skim Milk at Beyu Blue Coffee\n",
      "   Score: 0.420\n",
      "   Iced Mint 2 B U Skim Milk from Beyu Blue Coffee. Available during Specialty Drinks. Nutrition: 190 calories, 5g protein, 2g fat, 39g carbs, 1g fiber, ...\n",
      "\n",
      "3. Latte Skim Milk at Beyu Blue Coffee\n",
      "   Score: 0.419\n",
      "   Latte Skim Milk from Beyu Blue Coffee. Available during Specialty Drinks. Nutrition: 60 calories, 6g protein, 9g carbs, 9g sugars, 80mg sodium. Dietar...\n",
      "\n",
      " Query: 'heart healthy low sodium'\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████████| 1/1 [00:00<00:00, 42.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Naan at Tandoor Indian Cuisine\n",
      "   Score: 0.387\n",
      "   Naan from Tandoor Indian Cuisine. Available during Lunch/Dinner. Nutrition: 220 calories, 6g protein, 1g fat, 45g carbs, 2g fiber, 80mg sodium. Dietar...\n",
      "\n",
      "2. Grilled Yellow Fin Tuna at J.B.'s Roast & Chops\n",
      "   Score: 0.384\n",
      "   Grilled Yellow Fin Tuna from J.B.'s Roast & Chops. Nutrition: 140 calories, 34g protein, 0g fat, 270mg sodium. Macros: 97% protein, 3% fat. Tags: very...\n",
      "\n",
      "3. Kidney Beans at Duke Marine Lab\n",
      "   Score: 0.372\n",
      "   Kidney Beans from Duke Marine Lab. Available during Lunch. Nutrition: 40 calories, 3g protein, 7g carbs, 2g fiber, 85mg sodium. Dietary: Vegan; Vegeta...\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test queries that match some potentnial use cases\n",
    "test_queries = [\n",
    "    \"high protein low calorie\",\n",
    "    \"I want to lean bulk\",\n",
    "    \"I need more fiber\",\n",
    "    \"keto friendly meal\",\n",
    "    \"low sugar option\",\n",
    "    \"heart healthy low sodium\",\n",
    "]\n",
    "\n",
    "print(\" TESTING RETRIEVAL ON QUERIES\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n Query: '{query}'\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    results = retrieve_top_k(query, menu_embeddings, documents, \n",
    "                            embedding_model, embedding_tokenizer, device, k=3)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. {result['item_name']} at {result['restaurant']}\")\n",
    "        print(f\"   Score: {result['score']:.3f}\")\n",
    "        print(f\"   {result['document'][:150]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Test: Check Tag Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking if retrieval matches tags correctly\n",
      "\n",
      "Query: 'high protein low calorie'\n",
      "Expected tags: ['high protein', 'low calorie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████████| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found tags: ['high protein', 'low calorie']\n",
      "Top result: Steak\n",
      "\n",
      "Query: 'keto friendly'\n",
      "Expected tags: ['keto friendly', 'low carb']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████████| 1/1 [00:00<00:00, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found tags: ['keto friendly', 'low carb']\n",
      "Top result: Mushroom\n",
      "\n",
      "Query: 'high fiber'\n",
      "Expected tags: ['fiber', 'digestive']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████████| 1/1 [00:00<00:00, 34.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found tags: ['fiber', 'digestive']\n",
      "Top result: Pita Crisps\n",
      "\n",
      "\n",
      " Tag matching test complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test that retrieval finds items with the right tags\n",
    "print(\" Checking if retrieval matches tags correctly\\n\")\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        'query': 'high protein low calorie',\n",
    "        'expected_tags': ['high protein', 'low calorie']\n",
    "    },\n",
    "    {\n",
    "        'query': 'keto friendly',\n",
    "        'expected_tags': ['keto friendly', 'low carb']\n",
    "    },\n",
    "    {\n",
    "        'query': 'high fiber',\n",
    "        'expected_tags': ['fiber', 'digestive']\n",
    "    },\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    query = test['query']\n",
    "    expected = test['expected_tags']\n",
    "    \n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Expected tags: {expected}\")\n",
    "    \n",
    "    results = retrieve_top_k(query, menu_embeddings, documents, \n",
    "                            embedding_model, embedding_tokenizer, device, k=1)\n",
    "    \n",
    "    top_result = results[0]['document'].lower()\n",
    "    \n",
    "    matches = [tag for tag in expected if tag in top_result]\n",
    "    \n",
    "    if matches:\n",
    "        print(f\" Found tags: {matches}\")\n",
    "    else:\n",
    "        print(f\"Expected tags not found\")\n",
    "    \n",
    "    print(f\"Top result: {results[0]['item_name']}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n Tag matching test complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 2 now has:\n",
    "-  Working embedding model \n",
    "-  Embeddings for all 1,600+ menu items\n",
    "-  Saved embeddings ready for retrieval\n",
    "-  Tested retrieval works on some potential queries\n",
    "-  Optimized for MPS\n",
    "\n",
    "### Performance on MPS:\n",
    "-  ~2-5 minutes for full dataset\n",
    "-  Much faster than CPU (10-15 min)\n",
    "-  Similar to CUDA performance\n",
    "\n",
    "### Test Results:\n",
    "Checked manually for results matching up\n",
    "- \"high protein low calorie\" → chicken, turkey, etc.\n",
    "- \"lean bulk\" → high protein items\n",
    "- \"high fiber\" → fiber-rich items\n",
    "- \"keto\" → low carb items\n",
    "\n",
    "### Files Created:\n",
    "- `models/menu_embeddings.npy` (embeddings)\n",
    "- `models/embedding_metadata.json` (metadata)\n",
    "\n",
    "### MPS Optimizations:\n",
    "- Device detection (mps)\n",
    "- Proper tensor movement to MPS\n",
    "- Batch size optimized for Apple Silicon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
